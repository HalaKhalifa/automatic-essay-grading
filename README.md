# ğŸ“ Automatic Essay Grading using Mistral-7B

An NLP project to automate essay grading using a fine-tuned transformer model on Hugging Face.

---

## ğŸ“š Overview

Manual grading is time-consuming and inconsistent. This project develops an automated essay grading system using a fine-tuned instruction-based **Mistral-7B** model. It takes a question, a reference answer, a student answer, and a mark scheme â€” and returns a **score** and **rationale**.

---

## ğŸ¯ Project Objectives

- âœ… Clean and structure essay grading data
- âœ… Format data for instruction tuning
- âœ… Fine-tune Mistral-7B with LoRA and Unsloth (4-bit)
- âœ… Evaluate predictions vs. human scores
- âœ… Deploy as a web app using Flask + Streamlit

---

## ğŸ—ï¸ Project Components

| Component       | Description                                                                 |
|-----------------|-----------------------------------------------------------------------------|
| `flask_grading_api.py` | Flask backend to query the HF model and serve grades              |
| `essay_grader_fixed.html` | Frontend form to submit answers and display results          |
| `mistral_model_with_tuning.ipynb` | Notebook for fine-tuning using Unsloth & LoRA         |
| `model_with_fine_tuning_results.csv` | CSV of predictions vs. true scores for evaluation |
| `.env`          | Stores Hugging Face token and model name securely                          |

---

## ğŸ§  Model

- **Name**: [`sue888888888888/essay_grader`](https://huggingface.co/sue888888888888/essay_grader)
- **Base**: `Mistral-7B-Instruct`
- **Quantization**: 4-bit via `bitsandbytes`
- **Fine-Tuning**: LoRA with Unsloth
- **Inputs**: question, reference answer, student answer, mark scheme
- **Output**: total score + explanation

---

## ğŸ“Š Evaluation Results

| Metric                    | Value   |
|---------------------------|---------|
| Accuracy                  | 92.5%   |
| MAE (Mean Absolute Error) | 0.075   |
| RMSE                      | 0.27    |
| F1 Score (Macro)          | 0.92    |
| Spearman Rank Correlation | 0.97    |
| Test Samples              | 40      |

---

## ğŸš€ Run the App

1. **Clone the repo**:
   ```bash
   git clone https://github.com/HalaKhalifa/automatic-essay-grading.git
   cd automatic-essay-grading
   ```
2. **Set up environment**:
   ```bash
    pip install -r requirements.txt
    ```
3. **Create a .env file**:
   ```bash
    HUGGINGFACE_TOKEN=your_hf_token
    ```
4. **Run Flask API**:
   ```bash
    python frontend/flask_grading_api.py
    ```
5. **Access the UI**:
    Visit http://localhost:5000 and test essay grading live.


## ğŸ”— Resources

ğŸ”— Model on Hugging Face
ğŸ”— Training Dataset
ğŸ”— GitHub Repo

## ğŸ‘©â€ğŸ’» Authors

- **Sama Shalabi**
- **Bissan Dwekat**
- **Hala Khalifeh**
