{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG5FePm0MJRb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "%pip install pip3-autoremove\n",
        "%pip-autoremove torch torchvision torchaudio -y\n",
        "%pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "%pip install unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5H5T2ZkRTeQ",
        "outputId": "ee317e1c-e4c9-4607-9ba9-01319a862013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "545983d8153f461b8a60c2e314b6588f",
            "5ee7d03269e940e4bb93d6b83a705d18",
            "fc27c143814a4f68bdfdcd65854200ef",
            "52f89c30c8234c3686511005c1e525fc",
            "1e7e69824b804f2391f9ea8596324868",
            "c82d0f6dd7b94c8b9d3c131e050fab4a",
            "2c2440f6c42c40a0bb8f5f394348e78b",
            "b7a4daf35aff4de681a7e1a343021c98",
            "2d5da554a19f4a81b66712f4655b0329",
            "17d8589d08bd4231818410dc5ea69724",
            "684f375cd95a488bb835fdb314aa3366",
            "918b29f2f21a4d299af370cfb88c1a9b",
            "8ef0339cf2964698ac9a2a2c83465138",
            "27f98e611c664a9dadcb82211c76b7b1",
            "241ed3984de346429b4dbc07cb21d636",
            "bc2f69689eb447a68bb9cfcd1e3cf185",
            "138624c807c4410193d4311ca238b856",
            "1c6a3f8522f24be2bae9cfa2072936f7",
            "18643c33c550465c82be8bacd8da927a",
            "6c3eed2dcbbd4e4f8ef472d64d4bbde1",
            "67e5cf7b3d444d0fa5abb75e37a0608d",
            "3c41dc666e5a4393b88671cdf9174641",
            "ff5953ff86454a8fbbefda9a3aab8875",
            "e4d6374390b44448a0a4a8b542d4009b",
            "06dcaf2d28704d519bd1516efa1d7fde",
            "aa5e787efd2440578f3a730d9fe2cd7d",
            "f171d880a29d4e3a9c3827af1a6571f8",
            "8c3118dc25814fd0b880cf6db7239f7e",
            "5b0e2de3f9544a2c9ed6e8a9bdd62e23",
            "419220a1b0324ab4ac117a2aeb8f066a",
            "58553efe20d84eab922b584bd541a230",
            "3e5f58250cc24bf6af085ec6bbed6ba2",
            "2408e1ab43b44bee967cc4f577cb65b4",
            "6a6803aa5c384bbb8eff036e389ee1a1",
            "929468960ac4432c8b53660d91c00d63",
            "ef760d2782f941f49ea3849c3d11766c",
            "21ead43f48f3483da1f8132aa25af4c2",
            "9375d4c6af224eafad8f1ce1bfe1edb2",
            "8f771c4b2792428882cc4a73b65be629",
            "9b3898950ef64cceb51bc5bcdfd5851f",
            "91fe3dc190194e2db3e6448bc85e4467",
            "0ae3a094400b444f9d01168719c0bd75",
            "ba49b7462be541ec85456893b87979b9",
            "1ce592158bdf46af8f93ac2eb111726a"
          ]
        },
        "id": "HiAILBncMZ-S",
        "outputId": "2cbfad44-af40-417e-d81f-6a75d5ac902e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.5.6: Fast Mistral patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.5.6 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "545983d8153f461b8a60c2e314b6588f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "updated_data.json:   0%|          | 0.00/41.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "918b29f2f21a4d299af370cfb88c1a9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/58 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff5953ff86454a8fbbefda9a3aab8875",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/58 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a6803aa5c384bbb8eff036e389ee1a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/58 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "7.043 GB of memory reserved.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 58 | Num Epochs = 9 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040/7,000,000,000 (0.60% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms12218588\u001b[0m (\u001b[33ms12218588-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250520_162928-iqp4214d</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/s12218588-student/huggingface/runs/iqp4214d' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/s12218588-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/s12218588-student/huggingface' target=\"_blank\">https://wandb.ai/s12218588-student/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/s12218588-student/huggingface/runs/iqp4214d' target=\"_blank\">https://wandb.ai/s12218588-student/huggingface/runs/iqp4214d</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 05:55, Epoch 7/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.277100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.511400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.764100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.246600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.743800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.718200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.438200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.391800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.324400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.327700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.365900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.290400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.259200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.219000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.181100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.162100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.129300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.164800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.162600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.176300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.103000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.105900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.109000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.127300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.103000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.100500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.150200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.077200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.083800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.092100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.059600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.051300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.052300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.047200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.057100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.047000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.049900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.053900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.048400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.044700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.040700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.035200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.043700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.039200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.036400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.046400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.039600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.032200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.032400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "369.7277 seconds used for training.\n",
            "6.16 minutes used for training.\n",
            "Peak reserved memory = 7.359 GB.\n",
            "Peak reserved memory for training = 0.316 GB.\n",
            "Peak reserved memory % of max memory = 49.922 %.\n",
            "Peak reserved memory for training % of max memory = 2.144 %.\n",
            "Below is an instruction that describes how to grade an essay, paired with an input that provides the grading schema. Write a response that grades essays based on the mark schema provided.\n",
            "\n",
            "### Instruction:\n",
            "Grade this essay based on the following mark scheme:\n",
            "1: Defines photosynthesis correctly\n",
            "2: Mentions sunlight as an energy source\n",
            "3: Includes carbon dioxide and water as inputs\n",
            "4: Mentions oxygen or glucose as products \n",
            "\n",
            "### Input:\n",
            "What is photosynthesis?\n",
            "Reference Answer: Photosynthesis is the process by which green plants make their own food using sunlight, carbon dioxide, and water. The process occurs in the chloroplasts and produces glucose and oxygen as end products.\n",
            "Student Answer: Photosynthesis is when plants eat sunlight and turn it into food and air.\n",
            "\n",
            "### Response:\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %%capture\n",
        "# # Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "# !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "# !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "\n",
        "\"\"\"* We support Llama, Mistral, CodeLlama, TinyLlama, Vicuna, Open Hermes etc\n",
        "* And Yi, Qwen ([llamafied](https://huggingface.co/models?sort=trending&search=qwen+llama)), Deepseek, all Llama, Mistral derived archs.\n",
        "* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n",
        "* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n",
        "* With [PR 26037](https://github.com/huggingface/transformers/pull/26037), we support downloading 4bit models **4x faster**! [Our repo](https://huggingface.co/unsloth) has Llama, Mistral 4bit models.\n",
        "* [**NEW**] We make Gemma 6 trillion tokens **2.5x faster**! See our [Gemma notebook](https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing)\n",
        "\"\"\"\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
        "    \"unsloth/llama-2-13b-bnb-4bit\",\n",
        "    \"unsloth/codellama-34b-bnb-4bit\",\n",
        "    \"unsloth/tinyllama-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n",
        "    \"unsloth/gemma-2b-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\"\"\"We now add LoRA adapters so we only need to update 1 to 10% of all parameters!\"\"\"\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes how to grade an essay, paired with an input that provides the grading schema. Write a response that grades essays based on the mark schema provided.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # Add EOS token to stop generation\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    texts = []\n",
        "    for q, ra, sa, ms, score in zip(examples[\"question\"], examples[\"reference_answer\"], examples[\"student_answer\"], examples[\"mark_scheme\"], examples[\"score\"]):\n",
        "        # Convert mark_scheme dict to string\n",
        "        mark_scheme_str = \"\\n\".join([f\"{k}: {v}\" for k, v in ms.items()])\n",
        "        instruction = \"Grade this essay based on the following mark scheme:\\n\" + mark_scheme_str\n",
        "        input_text = f\"Question: {q}\\nReference Answer: {ra}\\nStudent Answer: {sa}\"\n",
        "        output_text = str(score)\n",
        "\n",
        "        # Format full prompt\n",
        "        text = alpaca_prompt.format(instruction, input_text, output_text) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\": texts }\n",
        "\n",
        "# Load dataset and apply formatting\n",
        "dataset = load_dataset(\"sue888888888888/essay_grading_for_instruction_tuning\", split=\"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    from trl import SFTTrainer\n",
        "    from transformers import TrainingArguments\n",
        "    from unsloth import is_bfloat16_supported\n",
        "\n",
        "    trainer = SFTTrainer(\n",
        "        model = model,\n",
        "        tokenizer = tokenizer,\n",
        "        train_dataset = dataset,\n",
        "        dataset_text_field = \"text\",\n",
        "        max_seq_length = max_seq_length,\n",
        "        dataset_num_proc = 2,\n",
        "        packing = False, # Can make training 5x faster for short sequences.\n",
        "        args = TrainingArguments(\n",
        "            per_device_train_batch_size = 2,\n",
        "            gradient_accumulation_steps = 4,\n",
        "            warmup_steps = 5,\n",
        "            max_steps = 60, # Set num_train_epochs = 1 for full training runs\n",
        "            learning_rate = 2e-4,\n",
        "            fp16 = not is_bfloat16_supported(),\n",
        "            bf16 = is_bfloat16_supported(),\n",
        "            logging_steps = 1,\n",
        "            optim = \"adamw_8bit\",\n",
        "            weight_decay = 0.01,\n",
        "            lr_scheduler_type = \"linear\",\n",
        "            seed = 3407,\n",
        "            output_dir = \"outputs\",\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    #@title Show current memory stats\n",
        "    gpu_stats = torch.cuda.get_device_properties(0)\n",
        "    start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "    max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "    print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "    print(f\"{start_gpu_memory} GB of memory reserved.\")\n",
        "\n",
        "    trainer_stats = trainer.train()\n",
        "\n",
        "    #@title Show final memory and time stats\n",
        "    used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "    used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "    used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "    lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "    print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "    print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "    print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "    print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "    print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "    print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n",
        "\n",
        "\n",
        "    # alpaca_prompt = Copied from above\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "    inputs = tokenizer(\n",
        "    [\n",
        "        alpaca_prompt.format(\n",
        "            \"Grade this essay based on the following mark scheme:\\n1: Defines photosynthesis correctly\\n2: Mentions sunlight as an energy source\\n3: Includes carbon dioxide and water as inputs\\n4: Mentions oxygen or glucose as products \", # instruction\n",
        "\n",
        "            \"What is photosynthesis?\\nReference Answer: Photosynthesis is the process by which green plants make their own food using sunlight, carbon dioxide, and water. The process occurs in the chloroplasts and produces glucose and oxygen as end products.\\nStudent Answer: Photosynthesis is when plants eat sunlight and turn it into food and air.\", # input\n",
        "\n",
        "            \"\", # output - leave this blank for generation!\n",
        "        )\n",
        "    ], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "    tokenizer.batch_decode(outputs)\n",
        "\n",
        "    decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    print(decoded_output[0])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# %%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byu1wJZYZQ9Q",
        "outputId": "eb3ffdd9-cc03-4b84-d05f-729c8679d979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: Tesla T4\n",
            "Error loading fine-tuned model: Unsloth: Failed to load model. Both AutoConfig and PeftConfig loading failed.\n",
            "\n",
            "AutoConfig error: Unrecognized model in outputs. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth\n",
            "\n",
            "PeftConfig error: Can't find 'adapter_config.json' at 'outputs'\n",
            "\n",
            "\n",
            "Falling back to base model (unsloth/mistral-7b-instruct-v0.2-bnb-4bit)\n",
            "==((====))==  Unsloth 2025.5.6: Fast Mistral patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "No test split found. Using 12 examples from train split for evaluation\n",
            "Starting evaluation on 50 samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:47<00:00,  3.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== EVALUATION METRICS ===\n",
            "accuracy: 0.3333\n",
            "mae: 1.3333\n",
            "mse: 4.0000\n",
            "rmse: 2.0000\n",
            "f1_macro: 0.2111\n",
            "\n",
            "=== SAMPLE RESULTS ===\n",
            "                                            question  true_score  pred_score  \\\n",
            "0                 What are renewable energy sources?           0         0.0   \n",
            "1                           What is the water cycle?           0         1.0   \n",
            "2                        Why is recycling important?           4         4.0   \n",
            "3                 Describe how photosynthesis works.           0         NaN   \n",
            "4                        Why is recycling important?           3         4.0   \n",
            "5                                 What is democracy?           0         1.0   \n",
            "6                         Explain how gravity works.           0         1.0   \n",
            "7                            What is photosynthesis?           0         0.0   \n",
            "8                            What is photosynthesis?           0         4.0   \n",
            "9  What is the function of the heart in the human...           0         NaN   \n",
            "\n",
            "   correct  \n",
            "0     True  \n",
            "1    False  \n",
            "2     True  \n",
            "3    False  \n",
            "4    False  \n",
            "5    False  \n",
            "6    False  \n",
            "7     True  \n",
            "8    False  \n",
            "9    False  \n",
            "\n",
            "=== SCORE DISTRIBUTION ===\n",
            "True scores distribution:\n",
            "true_score\n",
            "0    10\n",
            "3     1\n",
            "4     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Predicted scores distribution:\n",
            "pred_score\n",
            "0.0    2\n",
            "1.0    3\n",
            "4.0    4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Detailed results saved to 'evaluation_results.csv'\n",
            "\n",
            "=== ERROR ANALYSIS ===\n",
            "Examples with largest errors:\n",
            "\n",
            "Question: What is photosynthesis?\n",
            "True score: 0, Predicted: 4.0, Error: 4.0\n",
            "\n",
            "Question: What is the purpose of the digestive system?\n",
            "True score: 0, Predicted: 4.0, Error: 4.0\n",
            "\n",
            "Question: What is the water cycle?\n",
            "True score: 0, Predicted: 1.0, Error: 1.0\n",
            "\n",
            "Question: Why is recycling important?\n",
            "True score: 3, Predicted: 4.0, Error: 1.0\n",
            "\n",
            "Question: What is democracy?\n",
            "True score: 0, Predicted: 1.0, Error: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, f1_score\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Load fine-tuned model ---\n",
        "max_seq_length = 2048\n",
        "dtype = None  # Auto detection\n",
        "load_in_4bit = True\n",
        "\n",
        "# Check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    print(\"No GPU available. Using CPU (will be slow).\")\n",
        "    device = \"cpu\"\n",
        "\n",
        "# Path to your fine-tuned model (change if needed)\n",
        "model_path = \"outputs\"  # The output_dir from your training script\n",
        "\n",
        "try:\n",
        "    # Load the model - if this fails, may need to specify the exact checkpoint\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = model_path,\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    FastLanguageModel.for_inference(model)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading fine-tuned model: {e}\")\n",
        "    print(\"Falling back to base model (unsloth/mistral-7b-instruct-v0.2-bnb-4bit)\")\n",
        "\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model)\n",
        "\n",
        "# --- Prepare evaluation dataset ---\n",
        "# Load test split or use a portion of train data if test not available\n",
        "try:\n",
        "    eval_dataset = load_dataset(\"sue888888888888/essay_grading_for_instruction_tuning\", split=\"test\")\n",
        "    print(f\"Loaded test split with {len(eval_dataset)} examples\")\n",
        "except:\n",
        "    # If no test split, use a portion of train data\n",
        "    dataset = load_dataset(\"sue888888888888/essay_grading_for_instruction_tuning\", split=\"train\")\n",
        "    # Use 20% of data for evaluation\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    eval_dataset = dataset.select(range(train_size, len(dataset)))\n",
        "    print(f\"No test split found. Using {len(eval_dataset)} examples from train split for evaluation\")\n",
        "\n",
        "# --- Define prompt template ---\n",
        "# Same template as used in training\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes how to grade an essay, paired with an input that provides the grading schema. Write a response that grades essays based on the mark schema provided.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "# --- Evaluation function ---\n",
        "def evaluate_model(model, tokenizer, dataset, num_samples=None):\n",
        "    if num_samples is not None:\n",
        "        if num_samples > len(dataset):\n",
        "            num_samples = len(dataset)\n",
        "        indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "        dataset = dataset.select(indices)\n",
        "\n",
        "    results = []\n",
        "    true_scores = []\n",
        "    pred_scores = []\n",
        "\n",
        "    # Process each example in the dataset\n",
        "    for idx, example in enumerate(tqdm(dataset, desc=\"Evaluating\")):\n",
        "        # Format prompt\n",
        "        mark_scheme_str = \"\\n\".join([f\"{k}: {v}\" for k, v in example[\"mark_scheme\"].items()])\n",
        "        instruction = \"Grade this essay based on the following mark scheme:\\n\" + mark_scheme_str\n",
        "        input_text = f\"Question: {example['question']}\\nReference Answer: {example['reference_answer']}\\nStudent Answer: {example['student_answer']}\"\n",
        "\n",
        "        # Generate score\n",
        "        prompt = alpaca_prompt.format(instruction, input_text)\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Generate with modest parameters\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=64,\n",
        "            temperature=0.1,  # Low temperature for more deterministic output\n",
        "            top_p=0.9,\n",
        "            do_sample=False,  # Greedy decoding for evaluation\n",
        "            use_cache=True\n",
        "        )\n",
        "\n",
        "        # Decode the output\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract the generated score - look for the first number in the response\n",
        "        response_part = generated_text.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "        # Extract numeric score using regex\n",
        "        score_match = re.search(r'\\b(\\d+)\\b', response_part)\n",
        "        pred_score = int(score_match.group(1)) if score_match else None\n",
        "\n",
        "        true_score = example[\"score\"]\n",
        "\n",
        "        results.append({\n",
        "            \"index\": idx,\n",
        "            \"question\": example[\"question\"],\n",
        "            \"student_answer\": example[\"student_answer\"][:100] + \"...\",  # Truncate for display\n",
        "            \"true_score\": true_score,\n",
        "            \"pred_score\": pred_score,\n",
        "            \"correct\": pred_score == true_score if pred_score is not None else False,\n",
        "            \"full_response\": response_part\n",
        "        })\n",
        "\n",
        "        if pred_score is not None:\n",
        "            true_scores.append(true_score)\n",
        "            pred_scores.append(pred_score)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {}\n",
        "    if true_scores and pred_scores:\n",
        "        metrics[\"accuracy\"] = accuracy_score([int(s) for s in true_scores], [int(s) for s in pred_scores])\n",
        "        metrics[\"mae\"] = mean_absolute_error([int(s) for s in true_scores], [int(s) for s in pred_scores])\n",
        "        metrics[\"mse\"] = mean_squared_error([int(s) for s in true_scores], [int(s) for s in pred_scores])\n",
        "        metrics[\"rmse\"] = np.sqrt(metrics[\"mse\"])\n",
        "\n",
        "        # For multi-class F1\n",
        "        metrics[\"f1_macro\"] = f1_score(\n",
        "            [int(s) for s in true_scores],\n",
        "            [int(s) for s in pred_scores],\n",
        "            average='macro'\n",
        "        )\n",
        "\n",
        "    return results, metrics\n",
        "\n",
        "# --- Run evaluation ---\n",
        "# You can adjust the number of samples to evaluate if the dataset is large\n",
        "num_eval_samples = 50  # Change to None to evaluate on all samples\n",
        "\n",
        "print(f\"Starting evaluation on {num_eval_samples if num_eval_samples else len(eval_dataset)} samples...\")\n",
        "results, metrics = evaluate_model(model, tokenizer, eval_dataset, num_samples=num_eval_samples)\n",
        "\n",
        "# --- Display results ---\n",
        "# Summary metrics\n",
        "print(\"\\n=== EVALUATION METRICS ===\")\n",
        "for metric_name, value in metrics.items():\n",
        "    print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "# Create and display results dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n=== SAMPLE RESULTS ===\")\n",
        "print(results_df[[\"question\", \"true_score\", \"pred_score\", \"correct\"]].head(10))\n",
        "\n",
        "# Calculate distribution of scores\n",
        "if results_df[\"pred_score\"].notna().any():\n",
        "    print(\"\\n=== SCORE DISTRIBUTION ===\")\n",
        "    print(\"True scores distribution:\")\n",
        "    print(results_df[\"true_score\"].value_counts().sort_index())\n",
        "    print(\"\\nPredicted scores distribution:\")\n",
        "    print(results_df[\"pred_score\"].value_counts().sort_index())\n",
        "\n",
        "# Save detailed results to CSV\n",
        "results_df.to_csv(\"evaluation_results.csv\", index=False)\n",
        "print(\"\\nDetailed results saved to 'evaluation_results.csv'\")\n",
        "\n",
        "# --- Error Analysis ---\n",
        "if results_df[\"pred_score\"].notna().any():\n",
        "    print(\"\\n=== ERROR ANALYSIS ===\")\n",
        "\n",
        "    # Find examples with largest errors\n",
        "    results_df[\"error\"] = abs(results_df[\"true_score\"] - results_df[\"pred_score\"])\n",
        "    largest_errors = results_df.nlargest(5, \"error\")\n",
        "\n",
        "    print(\"Examples with largest errors:\")\n",
        "    for _, row in largest_errors.iterrows():\n",
        "        print(f\"\\nQuestion: {row['question']}\")\n",
        "        print(f\"True score: {row['true_score']}, Predicted: {row['pred_score']}, Error: {row['error']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFaAXzN5anIP",
        "outputId": "1f7e7698-e3de-4f51-a355-80617e5a3b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model's Response:\n",
            " Below is an instruction that describes how to grade an essay, paired with an input that provides the grading schema. Write a response that grades essays based on the mark schema provided.\n",
            "\n",
            "### Instruction:\n",
            "Grade this essay based on the following mark scheme:\n",
            "1: Defines gravity\n",
            "2: Mentions gravitational force\n",
            "3: Provides an example like an apple falling or planetary motion\n",
            "\n",
            "### Input:\n",
            "Question: What is gravity?\n",
            "Reference Answer: Gravity is the force that attracts objects with mass towards each other, like how the Earth pulls everything down.\n",
            "Student Answer: Gravity is the force .\n",
            "\n",
            "### Response:\n",
            "Based on the mark scheme provided, the student's answer would receive a grade of 1. The student has defined gravity as a force, which meets the first criterion of the mark scheme. However, the student's answer could be improved by adding more detail, such as mentioning that gravity attracts\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Enable 2x faster inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Define your input\n",
        "instruction = \"\"\"Grade this essay based on the following mark scheme:\n",
        "1: Defines gravity\n",
        "2: Mentions gravitational force\n",
        "3: Provides an example like an apple falling or planetary motion\"\"\"\n",
        "\n",
        "input_text = \"\"\"Question: What is gravity?\n",
        "Reference Answer: Gravity is the force that attracts objects with mass towards each other, like how the Earth pulls everything down.\n",
        "Student Answer: Gravity is the force .\"\"\"\n",
        "\n",
        "# Format the prompt\n",
        "custom_prompt = alpaca_prompt.format(instruction, input_text, \"\")  # Leave output blank\n",
        "\n",
        "# Tokenize and run inference\n",
        "inputs = tokenizer([custom_prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=64)\n",
        "\n",
        "# Decode and print the answer\n",
        "answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "print(\"Model's Response:\\n\", answer)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06dcaf2d28704d519bd1516efa1d7fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_419220a1b0324ab4ac117a2aeb8f066a",
            "max": 58,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58553efe20d84eab922b584bd541a230",
            "value": 58
          }
        },
        "0ae3a094400b444f9d01168719c0bd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "138624c807c4410193d4311ca238b856": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d8589d08bd4231818410dc5ea69724": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18643c33c550465c82be8bacd8da927a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6a3f8522f24be2bae9cfa2072936f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce592158bdf46af8f93ac2eb111726a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7e69824b804f2391f9ea8596324868": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21ead43f48f3483da1f8132aa25af4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba49b7462be541ec85456893b87979b9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ce592158bdf46af8f93ac2eb111726a",
            "value": "â€‡58/58â€‡[00:00&lt;00:00,â€‡67.93â€‡examples/s]"
          }
        },
        "2408e1ab43b44bee967cc4f577cb65b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "241ed3984de346429b4dbc07cb21d636": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e5cf7b3d444d0fa5abb75e37a0608d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3c41dc666e5a4393b88671cdf9174641",
            "value": "â€‡58/58â€‡[00:00&lt;00:00,â€‡633.21â€‡examples/s]"
          }
        },
        "27f98e611c664a9dadcb82211c76b7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18643c33c550465c82be8bacd8da927a",
            "max": 58,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c3eed2dcbbd4e4f8ef472d64d4bbde1",
            "value": 58
          }
        },
        "2c2440f6c42c40a0bb8f5f394348e78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d5da554a19f4a81b66712f4655b0329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c41dc666e5a4393b88671cdf9174641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e5f58250cc24bf6af085ec6bbed6ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "419220a1b0324ab4ac117a2aeb8f066a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f89c30c8234c3686511005c1e525fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17d8589d08bd4231818410dc5ea69724",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_684f375cd95a488bb835fdb314aa3366",
            "value": "â€‡41.4k/41.4kâ€‡[00:00&lt;00:00,â€‡2.69MB/s]"
          }
        },
        "545983d8153f461b8a60c2e314b6588f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ee7d03269e940e4bb93d6b83a705d18",
              "IPY_MODEL_fc27c143814a4f68bdfdcd65854200ef",
              "IPY_MODEL_52f89c30c8234c3686511005c1e525fc"
            ],
            "layout": "IPY_MODEL_1e7e69824b804f2391f9ea8596324868"
          }
        },
        "58553efe20d84eab922b584bd541a230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b0e2de3f9544a2c9ed6e8a9bdd62e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ee7d03269e940e4bb93d6b83a705d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82d0f6dd7b94c8b9d3c131e050fab4a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2c2440f6c42c40a0bb8f5f394348e78b",
            "value": "updated_data.json:â€‡100%"
          }
        },
        "67e5cf7b3d444d0fa5abb75e37a0608d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684f375cd95a488bb835fdb314aa3366": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a6803aa5c384bbb8eff036e389ee1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_929468960ac4432c8b53660d91c00d63",
              "IPY_MODEL_ef760d2782f941f49ea3849c3d11766c",
              "IPY_MODEL_21ead43f48f3483da1f8132aa25af4c2"
            ],
            "layout": "IPY_MODEL_9375d4c6af224eafad8f1ce1bfe1edb2"
          }
        },
        "6c3eed2dcbbd4e4f8ef472d64d4bbde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c3118dc25814fd0b880cf6db7239f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ef0339cf2964698ac9a2a2c83465138": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138624c807c4410193d4311ca238b856",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1c6a3f8522f24be2bae9cfa2072936f7",
            "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
          }
        },
        "8f771c4b2792428882cc4a73b65be629": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "918b29f2f21a4d299af370cfb88c1a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ef0339cf2964698ac9a2a2c83465138",
              "IPY_MODEL_27f98e611c664a9dadcb82211c76b7b1",
              "IPY_MODEL_241ed3984de346429b4dbc07cb21d636"
            ],
            "layout": "IPY_MODEL_bc2f69689eb447a68bb9cfcd1e3cf185"
          }
        },
        "91fe3dc190194e2db3e6448bc85e4467": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929468960ac4432c8b53660d91c00d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f771c4b2792428882cc4a73b65be629",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9b3898950ef64cceb51bc5bcdfd5851f",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=2):â€‡100%"
          }
        },
        "9375d4c6af224eafad8f1ce1bfe1edb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b3898950ef64cceb51bc5bcdfd5851f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa5e787efd2440578f3a730d9fe2cd7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e5f58250cc24bf6af085ec6bbed6ba2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2408e1ab43b44bee967cc4f577cb65b4",
            "value": "â€‡58/58â€‡[00:00&lt;00:00,â€‡1644.10â€‡examples/s]"
          }
        },
        "b7a4daf35aff4de681a7e1a343021c98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba49b7462be541ec85456893b87979b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2f69689eb447a68bb9cfcd1e3cf185": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82d0f6dd7b94c8b9d3c131e050fab4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d6374390b44448a0a4a8b542d4009b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3118dc25814fd0b880cf6db7239f7e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5b0e2de3f9544a2c9ed6e8a9bdd62e23",
            "value": "Map:â€‡100%"
          }
        },
        "ef760d2782f941f49ea3849c3d11766c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91fe3dc190194e2db3e6448bc85e4467",
            "max": 58,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ae3a094400b444f9d01168719c0bd75",
            "value": 58
          }
        },
        "f171d880a29d4e3a9c3827af1a6571f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc27c143814a4f68bdfdcd65854200ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7a4daf35aff4de681a7e1a343021c98",
            "max": 41357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d5da554a19f4a81b66712f4655b0329",
            "value": 41357
          }
        },
        "ff5953ff86454a8fbbefda9a3aab8875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d6374390b44448a0a4a8b542d4009b",
              "IPY_MODEL_06dcaf2d28704d519bd1516efa1d7fde",
              "IPY_MODEL_aa5e787efd2440578f3a730d9fe2cd7d"
            ],
            "layout": "IPY_MODEL_f171d880a29d4e3a9c3827af1a6571f8"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
